{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6421c943-7fcf-4855-90e1-0c7ec694db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1us/step\n",
      "Train samples: 25000\n",
      "Test samples: 25000\n",
      "Max word index: 9999\n",
      "Max review length: 2494\n",
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherl\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SimpleRNN model...\n",
      "\n",
      "Epoch 1/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 36ms/step - accuracy: 0.7093 - loss: 0.5490 - val_accuracy: 0.7569 - val_loss: 0.5625\n",
      "Epoch 2/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.7822 - loss: 0.4557 - val_accuracy: 0.7847 - val_loss: 0.4723\n",
      "Epoch 3/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.8660 - loss: 0.3177 - val_accuracy: 0.8020 - val_loss: 0.4408\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8020 - loss: 0.4408\n",
      "SimpleRNN Test Accuracy: 0.8020\n",
      "\n",
      " Training LSTM model...\n",
      "\n",
      "Epoch 1/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 96ms/step - accuracy: 0.6866 - loss: 91.8818 - val_accuracy: 0.7316 - val_loss: 0.5285\n",
      "Epoch 2/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 96ms/step - accuracy: 0.7842 - loss: 0.4538 - val_accuracy: 0.7299 - val_loss: 0.5384\n",
      "Epoch 3/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 99ms/step - accuracy: 0.8048 - loss: 189669888.0000 - val_accuracy: 0.6882 - val_loss: 0.6045\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.6882 - loss: 0.6045\n",
      "LSTM Test Accuracy: 0.6882\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, SimpleRNN, LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "max_features = 10000     # Vocabulary size\n",
    "maxlen = 100             # Max length for padding\n",
    "batch_size = 32\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "print(\"Train samples:\", len(x_train))\n",
    "print(\"Test samples:\", len(x_test))\n",
    "print(\"Max word index:\", max([max(seq) for seq in x_train]))\n",
    "print(\"Max review length:\", max([len(seq) for seq in x_train]))\n",
    "\n",
    "# Pad sequences\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "\n",
    "\n",
    "model_RNN = Sequential([\n",
    "    Embedding(max_features, 128, input_length=maxlen),\n",
    "    SimpleRNN(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_RNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"\\nTraining SimpleRNN model...\\n\")\n",
    "model_RNN.fit(x_train, y_train, batch_size=batch_size, epochs=3, validation_data=(x_test, y_test))\n",
    "\n",
    "rnn_score, rnn_acc = model_RNN.evaluate(x_test, y_test)\n",
    "print(f\"SimpleRNN Test Accuracy: {rnn_acc:.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# LSTM Model\n",
    "# ==============================\n",
    "model_LSTM = Sequential([\n",
    "    Embedding(max_features, 128, input_length=maxlen),\n",
    "    LSTM(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_LSTM.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"\\n Training LSTM model...\\n\")\n",
    "model_LSTM.fit(x_train, y_train, batch_size=batch_size, epochs=3, validation_data=(x_test, y_test))\n",
    "\n",
    "lstm_score, lstm_acc = model_LSTM.evaluate(x_test, y_test)\n",
    "print(f\"LSTM Test Accuracy: {lstm_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed20a23-6abb-4e0e-89c3-2840313e26e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
